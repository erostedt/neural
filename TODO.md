* Add catagorical crossentropy loss

* Make forwarding after training not requiring same batch size as training?

* Simplify construction of NN

* Clean up repo structure
* Remove unnecessary functions

* #pragma omp parallel for?
* Add more tests
* Use crossentropy/sigmoid/softmax simplification trick at last layer?
